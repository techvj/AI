{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import(\n",
    "    Event,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "llm = Ollama(model=\"llama3:latest\", request_timeout=120.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A pirate-themed joke, matey! Let's set sail for an analysis and critique of this swashbuckling attempt at humor.\n",
      "\n",
      "**The Setup**: The joke starts with a classic pirate phrase, \"Shiver me timbers!\" which immediately grabs the listener's attention. It's a clever way to introduce the joke and sets the tone for a playful, lighthearted tale. Score: 8/10\n",
      "\n",
      "**The Puns**: Ah, the arrrr-guments! The joke relies heavily on wordplay, substituting \"arguments\" with \"arrrr-guments,\" which is a clever play on words. Puns can be hit or miss, but in this case, it's a decent attempt to create a connection between the pirate setting and the reason for quitting his job. Score: 6/10\n",
      "\n",
      "**The Payoff**: The punchline relies on the listener making the connection between the pirate's dissatisfaction with arguments and his decision to quit his job. While it's not a particularly original or surprising twist, it does create a sense of closure and provides an opportunity for the teller to milk the joke for a bit longer (e.g., \"Get it? Arrrr-guments? Like, he was sick of all the bickering at work!\"). Score: 7/10\n",
      "\n",
      "**The Groan Factor**: The joke does have a bit of a groan-inducing quality to it, which is intentional. Pirate-themed humor often leans into cheesy and over-the-top antics, so this joke's reliance on wordplay and silly puns is in line with the genre. Score: 8/10 (because let's be honest, we've all been guilty of laughing at a bad pirate joke or two)\n",
      "\n",
      "**The Overall**: While it's not a laugh-out-loud masterpiece, the joke does have its charm. It's a fun, lighthearted attempt at humor that might elicit a chuckle from someone who appreciates silly puns and playful wordplay. Score: 7.5/10\n",
      "\n",
      "In conclusion, the joke is a decent effort that leans into pirate-themed humor, which can be a bit of a mixed bag. While it's not a masterpiece, it has its moments of cleverness and playfulness. So, if ye enjoy a good groan-inducing joke, this one might just make ye smile!\n"
     ]
    }
   ],
   "source": [
    "class JokeEvent(Event):\n",
    "    joke: str\n",
    "\n",
    "class JokeFlow(Workflow):\n",
    "    llm = Ollama(model=\"llama3:latest\", request_timeout=120.0)\n",
    "\n",
    "    @step\n",
    "    async def generate_joke(self, ev:StartEvent) -> JokeEvent:\n",
    "        topic = ev.topic\n",
    "\n",
    "        prompt = f\"write your best joke about {topic}.\"\n",
    "        response = await self.llm.acomplete(prompt)\n",
    "        return JokeEvent(joke=str(response))\n",
    "\n",
    "    @step\n",
    "    async def critique_joke(self, ev:JokeEvent) -> StopEvent:\n",
    "        joke = ev.joke\n",
    "\n",
    "        prompt = f\"Give a thorough analysis and critique of the following joke: {joke}\"\n",
    "        response = await self.llm.acomplete(prompt)\n",
    "        return StopEvent(result=str(response))\n",
    "\n",
    "\n",
    "w = JokeFlow(timeout=60, verbose=False)\n",
    "result = await w.run(topic=\"pirates\")\n",
    "print(str(result))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
